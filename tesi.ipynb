{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import yahooquery as yq\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# imports for the models\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulizia dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggi il file CSV\n",
    "df = pd.read_csv('./data/tesi28.csv', sep=';')\n",
    "#pulisci i nome dei df\n",
    "# sostituisci gli spazi con _ e togli le parentesi\n",
    "df.columns = [re.sub(r'\\(.*\\)', '', col) for col in df.columns]\n",
    "# Rimuovere lo spazio dagli header delle colonne alla fine e tra le parole\n",
    "df.columns = df.columns.str.rstrip(' ')\n",
    "df.columns = df.columns.str.rstrip('.')\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('/', '_')\n",
    "df.columns = df.columns.str.replace('.', '')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scarica i valori di borsa per ogni ticker, per ogni anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df['Ticker_symbol']\n",
    "valori_borsa = []\n",
    "tickers_non_scaricati=[]\n",
    "\n",
    "# Scarica i dati storici per ciascun ticker e anno\n",
    "for ticker in tickers:\n",
    "    yq_ticker = yq.Ticker(ticker+\".mi\")\n",
    "    for year in range(2023, 2013, -1):\n",
    "        # Specifica la data desiderata come \"YYYY-MM-DD\" (31 dicembre dell'anno specificato)\n",
    "        datainizio = f\"{year}-01-01\"\n",
    "        datafine = f\"{year}-01-10\"\n",
    "        print(ticker, year)\n",
    "        # Converti la data desiderata in un oggetto datetime\n",
    "        datainizio = datetime.datetime.strptime(datainizio, \"%Y-%m-%d\").date()\n",
    "        datafine = datetime.datetime.strptime(datafine, \"%Y-%m-%d\").date()\n",
    "\n",
    "\n",
    "        try:\n",
    "            val = yq_ticker.history(start=datainizio, end=datafine)['close'][-1]\n",
    "        except Exception as e:\n",
    "            print(e.__cause__)\n",
    "            val = \"NaN\"\n",
    "            tickers_non_scaricati.append(ticker)\n",
    "\n",
    "        print(ticker, val)\n",
    "        valori_borsa.append(val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valori_borsa))\n",
    "tickers_non_scaricati = set(tickers_non_scaricati)\n",
    "print(tickers_non_scaricati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregazione\n",
    "1. prendi info di interesse, moltiplica per ogni anno ogni osservazione \n",
    "2. aggiungi gli anni di interesse\n",
    "3. doppio ciclo for: per ogni riga df originale prendi i primi nove valori e trasponi il risultato, passa ai prossimi nove (secondo ciclo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crea df delle info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.concat([df.iloc[:, 0:5]] * 10)\n",
    "info.sort_index(inplace=True)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crea colonna degli anni, aggiungi a info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anni = [anno for anno in range(2022, 2012, -1)] * 28\n",
    "info['Anni'] = anni\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df degli indici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimuovi il carattere '\\n' e tutti quelli che seguono dalle intestazioni delle colonne\n",
    "df.columns = df.columns.str.replace(r'\\n.*', '', regex=True)\n",
    "df.columns = df.columns.str.rstrip('_')\n",
    "nomi_colonne = df.columns.unique()[5:]\n",
    "# prendi df di interesse, serve a semplificare gli indici\n",
    "indici = df.iloc[:, 5:]\n",
    "for i in indici.columns:\n",
    "    print(i)\n",
    "# crea nuovo df\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "col = 0\n",
    "#per ogni set di 10 valori riga di df originario INDICI\n",
    "for i in range(0, 140, 10):\n",
    "    \n",
    "    indice = []\n",
    "    #per ogni riga AZIENDA\n",
    "    for j in range(1,len(indici)+1):\n",
    "        # prendi i nove valori, trasponili e aggiungili al vettore dell'indice considerato\n",
    "        valori = indici.iloc[j-1:j, i:i+10].values[0]\n",
    "        valori = valori.T.tolist()\n",
    "        \n",
    "        indice= indice + valori\n",
    "        \n",
    "    # aggiungi colonna a new_df con insert\n",
    "    new_df.insert(col, nomi_colonne[col], indice)\n",
    "    col += 1\n",
    "\n",
    "\n",
    "for col in new_df.columns:\n",
    "    new_df[col] = new_df[col].str.replace(',' , '.').astype(float)\n",
    "    #print(type(X[col]))\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggiungi anche valori azionari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggiungi i valori della borsa al df info\n",
    "info['Valori_Borsa'] = valori_borsa\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### esegui il join dei due dataframe, resetta gli indici!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetta indici\n",
    "info = info.reset_index(drop=True)\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "#esegui il join\n",
    "dati_puliti = info.join(new_df)\n",
    "dati_puliti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESEGUI SE NON VUOI AZIENDE SENZA VALORI DI BORSA\n",
    "##### ripulisci i dati, togli le aziende che non hanno valori di borsa per almeno un anno e calcola gli indici per ogni azienda\n",
    "i valori di borsa non sono presenti in quanto alcune di queste aziende non erano quotate durante il periodo di analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina le aziende tramite una maschera\n",
    "tickers_non_scaricati = list(set(tickers_non_scaricati))\n",
    "maschera = dati_puliti['Ticker_symbol'].isin(tickers_non_scaricati)\n",
    "dati_puliti = dati_puliti[~maschera]\n",
    "#df_pulito = df_pulito.drop(columns=[\"Unnamed: 0\"])\n",
    "dati_puliti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESEGUI PER SALVARE DF DELLE AZIENDE CHE NON HANNO ALCUNI VALORI DI BORSA\n",
    "DF È PIÙ PICCOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_puliti.to_csv(\"./data/dati_puliti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESEGUI PER SALVARE DF DI TUTTE LE AZIENDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_puliti.to_csv(\"./data/dati_puliti28.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crea df di settori e industrie delle varie aziende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = list(tickers)\n",
    "#print(tickers_list)\n",
    "stocks_info = []\n",
    "non_processed = []\n",
    "for ticker in tickers_list:\n",
    "    ticker = ticker+\".mi\"\n",
    "    #print(ticker)\n",
    "    yf_ticker = yq.Ticker(ticker)\n",
    "    try:\n",
    "        stocks_info.append({\n",
    "            'ticker'    : ticker,\n",
    "            'name'      : yf_ticker.quote_type[ticker]['shortName'],\n",
    "            'industry'  : yf_ticker.asset_profile[ticker]['industry'],\n",
    "            'sector'    : yf_ticker.asset_profile[ticker]['sector'],\n",
    "        })\n",
    "    except:\n",
    "        non_processed.append(ticker)\n",
    "\n",
    "print(non_processed)\n",
    "t = pd.DataFrame(stocks_info)\n",
    "t['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crea per visualizzare industrie e settori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = pd.DataFrame(pd.DataFrame(t['sector'].value_counts())['count'])\n",
    "industries = pd.DataFrame(pd.DataFrame(t['industry'].value_counts())['count'])\n",
    "print(sectors)\n",
    "print(industries)\n",
    "\n",
    "fig_sectors = px.pie(sectors, values='count', names=sectors.index, title=\"settori\")\n",
    "fig_industry = px.pie(industries, \n",
    "                    values=\"count\",\n",
    "                    names=industries.index, \n",
    "                    title=\"industrie\",\n",
    "                    height=600,\n",
    "                    )\n",
    "fig_sectors.show()\n",
    "fig_industry.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distribuzioni delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una griglia 5x3 di subplot\n",
    "fig = make_subplots(rows=5, cols=3)\n",
    "car_indici = []\n",
    "# Cicla attraverso le colonne a partire dalla 7a\n",
    "for idx, col_name in enumerate(df.columns[7:]):\n",
    "    # Calcola la riga e la colonna corrispondenti nella griglia 5x3\n",
    "    row = idx // 3 + 1\n",
    "    col = idx % 3 + 1\n",
    "\n",
    "    # Aggiungi un grafico a questa posizione\n",
    "    histogram = px.box(df, x=col_name, )\n",
    "    fig.add_trace(histogram.data[0], row=row, col=col)\n",
    "\n",
    "    # Aggiungi titoli agli assi x e y\n",
    "    fig.update_xaxes(title_text=col_name, row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Frequenza', row=row, col=col)\n",
    "\n",
    "    #calcola media, min, max, dev std, \n",
    "    car_indici.append({\n",
    "        'indice' : col_name,\n",
    "        'media'  : df[col_name].mean(),\n",
    "        'min'    : df[col_name].min(),\n",
    "        'max'    : df[col_name].max(),\n",
    "        'dev std': df[col_name].std(),\n",
    "        'curtosi': df[col_name].kurtosis(),\n",
    "        'skew'   : df[col_name].skew()\n",
    "        \n",
    "    })\n",
    "\n",
    "# Aggiungi un layout per personalizzare il titolo e le dimensioni\n",
    "fig.update_layout(\n",
    "    title='Distribuzioni degli indici',\n",
    "    height=1000,  # Imposta l'altezza della griglia\n",
    "    width=1200    # Imposta la larghezza della griglia\n",
    ")\n",
    "\n",
    "# Visualizza la griglia\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_indici = pd.DataFrame(car_indici)\n",
    "car_indici.set_index('indice')\n",
    "car_indici.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scatter variabili log e non log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "for indice in df.columns[7:]:\n",
    "    # Creare una figura con subplots\n",
    "    fig = make_subplots(rows=1, cols=2,)\n",
    "    \n",
    "    for tick_symbol in df['Ticker_symbol'].unique():\n",
    "        # Filtrare il DataFrame per il Ticker_symbol corrente\n",
    "        df_subset = df[df['Ticker_symbol'] == tick_symbol]\n",
    "        \n",
    "        # Creare lo scatter plot con i valori di borsa originali\n",
    "        scatter1 = go.Scatter(x=df_subset[indice], y=df_subset[\"log_Valori_Borsa\"], mode='markers', name=f'Ticker {tick_symbol}')\n",
    "        \n",
    "        # Aggiungere la traccia al primo subplot\n",
    "        fig.add_trace(scatter1, row=1, col=1)\n",
    "        \n",
    "        # Creare lo scatter plot con i valori di borsa trasformati con il logaritmo\n",
    "        scatter2 = go.Scatter(x=df_subset[indice], y=df_subset[\"Valori_Borsa\"], mode='markers', name=f'Ticker {tick_symbol}')\n",
    "        \n",
    "        # Aggiungere la traccia al secondo subplot\n",
    "        fig.add_trace(scatter2, row=1, col=2)\n",
    "    \n",
    "    # Aggiornare la disposizione del layout\n",
    "    fig.update_layout(title_text=f'Relazione tra {indice} e Valori Borsa', showlegend=False)\n",
    "    \n",
    "    # Aggiungere le etichette degli assi y\n",
    "    fig.update_yaxes(title_text='Log Valori Borsa', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Valori Borsa', row=1, col=2)\n",
    "    \n",
    "    # Mostrare la figura\n",
    "    fig.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mostra le correlazioni tra i valori di borsa e tutti gli indici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "correlation_matrix = df.iloc[:, 6:].corr()\n",
    "# Crea una maschera per nascondere la parte superiore della matrice\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Crea una figura per il grafico\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Personalizza l'aspetto della heatmap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", mask=mask, cmap=cmap)\n",
    "\n",
    "# Visualizza il grafico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stima del modello\n",
    "**attenzione** al path usato, esistono due file: uno con tutte le aziende (dati_puliti28) e uno con solo le aziende che contengono valori di borsa(dati_puliti)\n",
    "stiamo effettuando una trasformazione logaritmica della variabile dipendente: valori_borsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dati_puliti28.csv', sep=',')\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "#calcola i logaritmo dei valori di borsa\n",
    "df['Valori_Borsa'] = np.log(df['Valori_Borsa'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepara il df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea le variabili dummy\n",
    "df_dummies = pd.get_dummies(df[\"Ticker_symbol\"])\n",
    "print(df_dummies)\n",
    "# unsci le dummies al df\n",
    "df_con_dummies = df.join(df_dummies)\n",
    "df_con_dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the regression equation. Note that we are leaving out one dummy variable so as to avoid perfect Multicollinearity between the 7 dummy variables. la dummy omessa è BAN \n",
    "#RIVEDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ripulisci il df da valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_dummies = df_con_dummies.dropna()\n",
    "df_con_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definisci le variabili da usare nel modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisce le var dipendenti e indipendenti\n",
    "y_var_name = 'Valori_Borsa'\n",
    "x_var_names =  [\n",
    "    'Anni',\n",
    "    'Indice_corrente', \n",
    "    'Indice_di_liquidità',\n",
    "    'Rotaz_cap_investito', \n",
    "    'Rotaz_cap_cir_lordo',\n",
    "    'Redditività_del_totale_attivo',\n",
    "    'Redditività_di_tutto_il_capitale_investito',\n",
    "    'Redditività_delle_vendite', \n",
    "    'Redditività_del_capitale_proprio',\n",
    "    'Indice_di_copertura_delle_immob', \n",
    "    'Costo_denaro_a_prestito',\n",
    "    'Oneri_finanz_su_fatt', \n",
    "    'Grado_di_copertura_degli_interessi_passivi',\n",
    "    'Debiti_v_banche_su_fatt', \n",
    "    'Debt_Equity_ratio'\n",
    "    ]\n",
    "\n",
    "unit_names = [\n",
    "    'MARR', \n",
    "    'PIA', \n",
    "    'BRE', \n",
    "    'DAN', \n",
    "    'BC', \n",
    "    'CLI', \n",
    "    'ELC', \n",
    "    'GPI', \n",
    "    'SRI',\n",
    "    'ALA', \n",
    "    'ICF', \n",
    "    'ENV', \n",
    "    'MASI', \n",
    "    'SVS', \n",
    "    'STAR7', \n",
    "    'SCK', \n",
    "    'MARP', \n",
    "    'ITD',\n",
    "    'VIM', \n",
    "    'MDC', \n",
    "    'ILP', \n",
    "    'CFL', \n",
    "    'FCM', \n",
    "    'FVI', \n",
    "    'PLT', \n",
    "    'LDB', \n",
    "    'FOS',\n",
    "    'BAN'\n",
    "    ]\n",
    "\n",
    "#only_value = [x for x in unit_names if x not in tickers_non_scaricati]\n",
    "#unit_names = only_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definisci espressione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdv_expr = y_var_name + ' ~ '\n",
    "i = 0\n",
    "for x_var_name in x_var_names:\n",
    "    if i > 0:\n",
    "        lsdv_expr = lsdv_expr + ' + ' + x_var_name\n",
    "    else:\n",
    "        lsdv_expr = lsdv_expr + x_var_name\n",
    "    i = i + 1\n",
    "for dummy_name in unit_names[:-1]:\n",
    "    lsdv_expr = lsdv_expr + ' + ' + dummy_name\n",
    " \n",
    "print('Regression expression for OLS with dummies=' + lsdv_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdv_model = smf.ols(formula=lsdv_expr, data=df_con_dummies)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "print(lsdv_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_results = lsdv_model_results.get_robustcov_results(cov_type='HAC', maxlags=2, groups=df['ID'], time=df['Anni'])\n",
    "\n",
    "print(robust_results.summary())\n",
    "#robust_results.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC per trasformazione logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_results.aic + (2*sum(df['Valori_Borsa'].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC per dati senza trasformazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## addestramento modello con split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anni = df['Anni'].unique()[1:9]\n",
    "risultati = {}\n",
    "# Ciclo per ogni anno e crea set di addestramento e test\n",
    "for anno_test in anni:\n",
    "    \n",
    "    # dividi il df\n",
    "    train_data = df_con_dummies[df_con_dummies['Anni'] != anno_test]  # Utilizza tutti gli anni precedenti a quello di test\n",
    "    test_data = df_con_dummies[df_con_dummies['Anni'] == anno_test]  # Utilizza solo l'anno di test\n",
    "\n",
    "    # crea il modello\n",
    "    lsdv_model = smf.ols(formula=lsdv_expr, data=train_data)\n",
    "    lsdv_model_results = lsdv_model.fit()\n",
    "    robust_results = lsdv_model_results.get_robustcov_results(cov_type='HAC', maxlags=2, groups=df['ID'], time=df['Anni'])\n",
    "    \n",
    "    # previsione\n",
    "    y_pred = robust_results.predict(test_data)\n",
    "    \n",
    "    #ATTENZIONE\n",
    "    #leva commento a riga sotto se val borsa sono trasformati\n",
    "    y_pred = np.e**y_pred\n",
    "    \n",
    "    # per eliminare il fatto che ci siano dei Nan dobbiamo\n",
    "    # aggregare le due colonne in un df e poi usare dropna()\n",
    "    df_prev = pd.DataFrame({\n",
    "        'ID': test_data.index,\n",
    "        'Anni': test_data['Anni'],\n",
    "        'test_data' : test_data[y_var_name],\n",
    "        'y_pred' : y_pred\n",
    "    })\n",
    "    print(anno_test)\n",
    "    print(df_prev)\n",
    "    df_prev = df_prev.dropna()\n",
    "\n",
    "    # calcolo rmse\n",
    "    rmse = np.sqrt(mean_squared_error(df_prev['test_data'], df_prev['y_pred']))\n",
    "\n",
    "    # Salva i risultati per l'anno corrente\n",
    "    risultati[anno_test] = rmse\n",
    "\n",
    "\n",
    "# Calcola la media del RMSE su tutti gli anni di test\n",
    "media_rmse = sum(risultati.values()) / len(risultati)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(\"RMSE medio su tutti gli anni:\", media_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 80-20: 331.7351112295058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "risultati = {}\n",
    "\n",
    "    \n",
    "# ordina il df secondo anno\n",
    "df = df_con_dummies.sort_values(by=\"Anni\")\n",
    "# dividi il df\n",
    "\n",
    "# Creare un set di addestramento e un set di test con uno split 80-20\n",
    "train_data, test_data = train_test_split(df, test_size=0.8, shuffle=False)\n",
    "\n",
    "\n",
    "# crea il modello\n",
    "lsdv_model = smf.ols(formula=lsdv_expr, data=train_data)\n",
    "lsdv_model_results = lsdv_model.fit()\n",
    "robust_results = lsdv_model_results.get_robustcov_results(cov_type='HAC', maxlags=2, groups=df['ID'], time=df['Anni'])\n",
    "\n",
    "# previsione\n",
    "y_pred = robust_results.predict(test_data)\n",
    "\n",
    "#ATTENZIONE\n",
    "#leva commento a riga sotto se val borsa sono trasformati\n",
    "y_pred = np.e**y_pred\n",
    "\n",
    "# per eliminare il fatto che ci siano dei Nan dobbiamo\n",
    "# aggregare le due colonne in un df e poi usare dropna()\n",
    "df_prev = pd.DataFrame({\n",
    "    'test_data' : test_data[y_var_name],\n",
    "    'y_pred' : y_pred\n",
    "})\n",
    "\n",
    "df_prev = df_prev.dropna()\n",
    "\n",
    "# calcolo rmse\n",
    "rmse = np.sqrt(mean_squared_error(df_prev['test_data'], df_prev['y_pred']))\n",
    "\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(\"RMSE 80-20:\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residui del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni le previsioni per tutte le righe nel dataframe\n",
    "predictions = lsdv_model_results.predict()\n",
    "\n",
    "# trasform predictions to the original scale and the share values\n",
    "predictions = np.e**predictions\n",
    "val_borsa = (np.e**df['Valori_Borsa']).dropna()\n",
    "#val_borsa = df['Valori_Borsa'].dropna()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(val_borsa, predictions))\n",
    "mae = mean_absolute_error(val_borsa, predictions)\n",
    "rsquared = lsdv_model_results.rsquared\n",
    "\n",
    "# Aggiungi i dati alla lista\n",
    "errors.append({\n",
    "    'Formula': 'log ' + lsdv_expr,\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'R-Squared': rsquared,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 2500)\n",
    "errors_df = pd.DataFrame(errors)\n",
    "\n",
    "err = pd.read_csv(\"./data/errori.csv\")\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crea df dei residui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsioni = df[['ID','Ticker_symbol','Anni', 'Valori_Borsa']].dropna()\n",
    "previsioni['Valori_Borsa'] = val_borsa\n",
    "previsioni['predictions'] = predictions\n",
    "#previsioni[previsioni['Ticker_symbol']=='LDB']\n",
    "previsioni['residui'] = previsioni['Valori_Borsa'] - previsioni['predictions'] \n",
    "previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsioni = df[['ID','Ticker_symbol','Anni', 'Valori_Borsa']].dropna()\n",
    "previsioni['predictions'] = robust_results.predict()\n",
    "previsioni['residui'] = previsioni['Valori_Borsa'] - previsioni['predictions'] \n",
    "previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy import stats\n",
    "\n",
    "# Calcola le correlazioni a vari lag\n",
    "lag_max = 6\n",
    "correlations = []\n",
    "\n",
    "for lag in range(1, lag_max+1):\n",
    "    correlation = previsioni['residui'].autocorr(lag=lag)\n",
    "    correlations.append(correlation)\n",
    "\n",
    "# Calcola le bande di significatività\n",
    "alpha = 0.05\n",
    "nobs = len(previsioni)\n",
    "z_critical = stats.norm.ppf(1 - alpha/2) / (nobs**0.5)\n",
    "lower_band = [-z_critical] * lag_max\n",
    "upper_band = [z_critical] * lag_max\n",
    "\n",
    "# Crea un grafico ACF con bande di significatività\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plot_acf(previsioni['residui'], lags=lag_max, ax=ax)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)  # Aggiunge una linea orizzontale a 0\n",
    "\n",
    "# Aggiunge bande di significatività\n",
    "ax.fill_between(range(1, lag_max+1), lower_band, upper_band, color='gray', alpha=0.2)\n",
    "\n",
    "plt.title('Autocorrelation Function (ACF) dei Residui')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "corrs = []\n",
    "for i in range(0,10):\n",
    "    \n",
    "    previsioni['res_lag' + str(i)] = previsioni.groupby(['ID'])['residui'].shift(i)\n",
    "\n",
    "    correlazione = previsioni['residui'].corr(previsioni['res_lag' + str(i)])\n",
    "    err_std = 1.96*(1/math.sqrt(previsioni['res_lag' + str(i)].count()))\n",
    "    corrs.append((correlazione - err_std ,\n",
    "    correlazione ,\n",
    "    correlazione + err_std))\n",
    "\n",
    "\n",
    "# Estrai i valori delle correlazioni e i range\n",
    "correlazioni = [x[1] for x in corrs]\n",
    "minimi = [x[0] for x in corrs]\n",
    "massimi = [x[2] for x in corrs]\n",
    "\n",
    "# Creare un DataFrame\n",
    "corrs = pd.DataFrame({'Lag': range(1,len(correlazioni)+1), 'Correlazione': correlazioni, 'Minimo': minimi, 'Massimo': massimi})\n",
    "# riportiamo solo 6 lag , oltre ha troppa incertezza\n",
    "corrs = corrs[:6]\n",
    "corrs\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Creare il grafico\n",
    "fig = go.Figure()\n",
    "\n",
    "# Aggiungere i valori di correlazione\n",
    "fig.add_trace(go.Bar(x=corrs['Lag'], y=corrs['Correlazione'], name='Correlazione'))\n",
    "\n",
    "# Aggiungere le linee per i range dell'intervallo di confidenza\n",
    "fig.add_trace(go.Scatter(x=corrs['Lag'], y=corrs['Minimo'], mode='lines', name='Minimo'))\n",
    "fig.add_trace(go.Scatter(x=corrs['Lag'], y=corrs['Massimo'], mode='lines', name='Massimo'))\n",
    "\n",
    "# Aggiungere layout\n",
    "fig.update_layout(title='Funzione di Autocorrelazione',\n",
    "                  xaxis_title='Lag',\n",
    "                  yaxis_title='Correlazione',\n",
    "                  xaxis=dict(tickmode='array', tickvals=corrs['Lag'], ticktext=corrs['Lag']))\n",
    "\n",
    "# Mostrare il grafico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crea grafico delle previsioni e residui per ogni azienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(previsioni, x=\"Anni\", y=\"residui\", color=\"Ticker_symbol\",\n",
    "              title=\"Relazione tra Anni e Residui del modello\",\n",
    "              labels={'residui': 'Residui', 'Anni': 'Anno'},\n",
    "              height=750)\n",
    "\n",
    "# Mostra il grafico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "controllo omoschedasticità, se sono omogenei lungo x rispetto a y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un grafico a dispersione dei residui rispetto alle previsioni\n",
    "plt.scatter(previsioni['predictions'], previsioni['residui'])\n",
    "plt.xlabel('Previsioni')\n",
    "plt.ylabel('Residui')\n",
    "plt.title('Grafico dei Residui vs. Valori previsti')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acf dei residui: controllo autocorrelazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "acf_residui = sm.tsa.acf(previsioni['residui'], nlags=13)\n",
    "plot_acf(acf_residui, title=f'ACF residui')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "controllo normalità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Esegue il test di Shapiro-Wilk\n",
    "statistica, p_value = shapiro(previsioni['residui'])\n",
    "\n",
    "# Stampa i risultati del test\n",
    "print(f'Statistica del test di Shapiro-Wilk: {statistica}')\n",
    "print(f'p-value del test di Shapiro-Wilk: {p_value}')\n",
    "\n",
    "# Confronta il p-value con un livello di significatività (e.g., 0.05)\n",
    "if p_value > 0.05:\n",
    "    print(\"Non abbiamo sufficienti prove per rifiutare l'ipotesi che i residui seguano una distribuzione normale.\")\n",
    "else:\n",
    "    print(\"Rifiutiamo l'ipotesi che i residui seguano una distribuzione normale.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il QQ-plot\n",
    "sm.qqplot(previsioni['residui'], line='s')  # 's' indica una linea di riferimento per una distribuzione normale\n",
    "plt.title('QQ-Plot dei Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covarianza tra errori e indici\n",
    "#### quarta condizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una griglia 5x3 di subplot\n",
    "fig = make_subplots(rows=5, cols=3)\n",
    "\n",
    "# Cicla attraverso le colonne a partire dalla 7a\n",
    "for idx, col_name in enumerate(df.columns[7:]):\n",
    "    # Calcola la riga e la colonna corrispondenti nella griglia 5x3\n",
    "    row = idx // 3 + 1\n",
    "    col = idx % 3 + 1\n",
    "\n",
    "    # Aggiungi un grafico a questa posizione\n",
    "    scatter = px.scatter(df.dropna(), y=previsioni['residui'], x=col_name)\n",
    "    fig.add_trace(scatter.data[0], row=row, col=col)\n",
    "\n",
    "    # Aggiungi titoli agli assi x e y\n",
    "    fig.update_xaxes(title_text=col_name, row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Errori', row=row, col=col)\n",
    "\n",
    "\n",
    "# Aggiungi un layout per personalizzare il titolo e le dimensioni\n",
    "fig.update_layout(\n",
    "    title='residui vs indici',\n",
    "    height=1000,  # Imposta l'altezza della griglia\n",
    "    width=1200    # Imposta la larghezza della griglia\n",
    ")\n",
    "\n",
    "# Visualizza la griglia\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distanza di Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcolare l'influenza e la distanza di Cook\n",
    "influence = robust_results.get_influence()\n",
    "cooks_distance = influence.cooks_distance\n",
    "\n",
    "# Stampa i valori di distanza di Cook\n",
    "print(cooks_distance[0])\n",
    "# Creare un array con gli indici delle osservazioni\n",
    "indices = range(len(cooks_distance[0]))\n",
    "\n",
    "# Creare il grafico a dispersione\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(indices, cooks_distance[0], c='blue', label='Distanza di Cook')\n",
    "\n",
    "# Aggiungere etichette e titoli\n",
    "plt.xlabel('Indice Osservazione')\n",
    "plt.ylabel('Distanza di Cook')\n",
    "plt.title('Distanza di Cook per Osservazione')\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsioni['cook'] = cooks_distance[0]\n",
    "previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona solo le colonne che ti interessano\n",
    "df_plot = previsioni[['Ticker_symbol', 'cook']]\n",
    "\n",
    "# Crea uno scatter plot\n",
    "fig = px.scatter(df_plot, x=df_plot.index, y='cook', color='Ticker_symbol', \n",
    "                 title='Scatter plot della Distanza di Cook per Previsione', \n",
    "                 labels={'index': 'Indice Previsione', 'cook': 'Distanza di Cook'},\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "\n",
    "# Aggiungi titoli e etichette\n",
    "fig.update_layout(xaxis_title='Indice Previsione', yaxis_title='Distanza di Cook', height=750)\n",
    "\n",
    "# Mostra il grafico\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
